# Machine learning system for Risk Assessment

This is a Machine Learning Model Risk Scoring and Monitoring project. The problem is to create, deploy, and monitor a risk assessment ML model that will estimate the attrition risk of each of the company's clients. Also setting up processes to re-train, re-deploy, monitor and report on the ML model.

## Prerequisites
- Python 3 required
- Virtualenv recommended

## Dependencies
This project dependencies is available in the ```requirements.txt``` file.

## Installation
Use the package manager [pip](https://pip.pypa.io/en/stable/) to install the dependencies from the ```requirements.txt```. Its recommended to install it in a separate [virtual environment](https://virtualenv.pypa.io/en/latest/).

```bash
pip3 install -r requirements.txt
```

## Project Structure
```bash
ðŸ“¦Dynamic-Risk-Assessment-System
 â”£
 â”£ ðŸ“‚data
 â”ƒ â”£ ðŸ“‚ingesteddata                 # Contains csv and metadata of the ingested data
 â”ƒ â”ƒ â”£ ðŸ“œfinaldata.csv
 â”ƒ â”ƒ â”— ðŸ“œingestedfiles.txt
 â”ƒ â”£ ðŸ“‚practicedata                 # Data used for practice mode initially
 â”ƒ â”ƒ â”£ ðŸ“œdataset1.csv
 â”ƒ â”ƒ â”— ðŸ“œdataset2.csv
 â”ƒ â”£ ðŸ“‚sourcedata                   # Data used for production mode
 â”ƒ â”ƒ â”£ ðŸ“œdataset3.csv
 â”ƒ â”ƒ â”— ðŸ“œdataset4.csv
 â”ƒ â”— ðŸ“‚testdata                     # Test data
 â”ƒ â”ƒ â”— ðŸ“œtestdata.csv
 â”£ ðŸ“‚model
 â”ƒ â”£ ðŸ“‚models                       # Models pickle, score, and reports for production mode
 â”ƒ â”ƒ â”£ ðŸ“œapireturns.txt
 â”ƒ â”ƒ â”£ ðŸ“œconfusionmatrix.png
 â”ƒ â”ƒ â”£ ðŸ“œlatestscore.txt
 â”ƒ â”ƒ â”£ ðŸ“œsummary_report.pdf
 â”ƒ â”ƒ â”— ðŸ“œtrainedmodel.pkl
 â”ƒ â”£ ðŸ“‚practicemodels               # Models pickle, score, and reports for practice mode
 â”ƒ â”ƒ â”£ ðŸ“œapireturns.txt
 â”ƒ â”ƒ â”£ ðŸ“œconfusionmatrix.png
 â”ƒ â”ƒ â”£ ðŸ“œlatestscore.txt
 â”ƒ â”ƒ â”£ ðŸ“œsummary_report.pdf
 â”ƒ â”ƒ â”— ðŸ“œtrainedmodel.pkl
 â”ƒ â”— ðŸ“‚production_deployment        # Deployed models and model metadata needed
 â”ƒ â”ƒ â”£ ðŸ“œingestedfiles.txt
 â”ƒ â”ƒ â”£ ðŸ“œlatestscore.txt
 â”ƒ â”ƒ â”— ðŸ“œtrainedmodel.pkl
 â”£ ðŸ“‚src
 â”ƒ â”£ ðŸ“œapicalls.py                  # Runs app endpoints
 â”ƒ â”£ ðŸ“œapp.py                       # Flask app
 â”ƒ â”£ ðŸ“œconfig.py                    # Config file for the project which depends on config.json
 â”ƒ â”£ ðŸ“œdeployment.py                # Model deployment script
 â”ƒ â”£ ðŸ“œdiagnostics.py               # Model diagnostics script
 â”ƒ â”£ ðŸ“œfullprocess.py               # Process automation
 â”ƒ â”£ ðŸ“œingestion.py                 # Data ingestion script
 â”ƒ â”£ ðŸ“œpretty_confusion_matrix.py   # Plots confusion matrix
 â”ƒ â”£ ðŸ“œreporting.py                 # Generates confusion matrix and PDF report
 â”ƒ â”£ ðŸ“œscoring.py                   # Scores trained model
 â”ƒ â”£ ðŸ“œtraining.py                  # Model training
 â”ƒ â”— ðŸ“œwsgi.py
 â”£ ðŸ“œconfig.json                    # Config json file
 â”£ ðŸ“œcronjob.txt                    # Holds cronjob created for automation
 â”£ ðŸ“œREADME.md
 â”— ðŸ“œrequirements.txt               # Projects required dependencies
```

## Steps Overview
1. **Data ingestion:** Automatically check if new data that can be used for model training. Compile all training data to a training dataset and save it to folder. 
2. **Training, scoring, and deploying:** Write scripts that train an ML model that predicts attrition risk, and score the model. Saves the model and the scoring metrics.
3. **Diagnostics:** Determine and save summary statistics related to a dataset. Time the performance of some functions. Check for dependency changes and package updates.
4. **Reporting:** Automatically generate plots and PDF document that report on model metrics and diagnostics. Provide an API endpoint that can return model predictions and metrics.
5. **Process Automation:** Create a script and cron job that automatically run all previous steps at regular intervals.

<img src="images/fullprocess.jpg" width=550 height=300>

## Usage

### 0- Run Flask App in separate terminal, run the rest of the steps in another terminal
```python
python3 app.py
```

### 1- Edit config.json file to use practice data

```bash
"input_folder_path": "practicedata",
"output_folder_path": "ingesteddata", 
"test_data_path": "testdata", 
"output_model_path": "practicemodels", 
"prod_deployment_path": "production_deployment"
```

### 2- Run data ingestion
```python
cd src
python3 ingestion.py
```
Artifacts output:
```
data/ingesteddata/finaldata.csv
data/ingesteddata/ingestedfiles.txt
```

### 3- Model training
```python
python3 training.py
```
Artifacts output:
```
models/practicemodels/trainedmodel.pkl
```

###  4- Model scoring 
```python
python3 scoring.py
```
Artifacts output: 
```
models/practicemodels/latestscore.txt
``` 

### 5- Model deployment
```python
python3 deployment.py
```
Artifacts output:
```
model/prod_deployment_path/ingestedfiles.txt
model/prod_deployment_path/trainedmodel.pkl
model/prod_deployment_path/latestscore.txt
``` 

### 6- Run diagnostics
```python
python3 diagnostics.py
```

### 7- Run reporting
```python
python3 reporting.py
```
Artifacts output:
```
models/practicemodels/confusionmatrix.png
models/practicemodels/summary_report.pdf
```

### 8- Run API endpoints
```python
python3 apicalls.py
```
Artifacts output:
```
models/practicemodels/apireturns.txt
```

### 9- Edit config.json file to use production data

```bash
"input_folder_path": "sourcedata",
"output_folder_path": "ingesteddata", 
"test_data_path": "testdata", 
"output_model_path": "models", 
"prod_deployment_path": "production_deployment"
```

### 10- Full process automation
```python
python3 fullprocess.py
```
### 11- Cron job

Start cron service
```bash
sudo service cron start
```

Edit crontab file
```bash
sudo crontab -e
```
   - Select **option 3** to edit file using vim text editor
   - Press **i** to insert a cron job
   - Write the cron job in ```cronjob.txt``` which runs ```fullprocces.py``` every 10 mins
   - Save after editing, press **esc key**, then type **:wq** and press enter
  
View crontab file
```bash
sudo crontab -l
```

